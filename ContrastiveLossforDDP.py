import torch
import torch.nn as nn
import torch.nn.functional as F

def get_positive_expectation(p_samples, measure='JSD', average_loss=True):
    import math

    import torch

    log_2 = math.log(2.)

    if measure == 'GAN':
        Ep = -torch.nn.functional.softplus(-p_samples)
    elif measure == 'JSD':
        Ep = log_2 - torch.nn.functional.softplus(-p_samples)
    elif measure == 'X2':
        Ep = p_samples**2
    elif measure == 'KL':
        Ep = p_samples + 1.
    elif measure == 'RKL':
        Ep = -torch.exp(-p_samples)
    elif measure == 'DV':
        Ep = p_samples
    elif measure == 'H2':
        Ep = 1. - torch.exp(-p_samples)
    elif measure == 'W1':
        Ep = p_samples
    else:
        raise ValueError('Unknown measure: {}'.format(measure))

    if average_loss:
        return Ep.mean()
    else:
        return Ep


def get_negative_expectation(q_samples, measure='JSD', average_loss=True):
    """Computes the negative part of a divergence / difference.

    Parameters
    ----------
    q_samples: torch.Tensor
        Negative samples.
    measure: str

    average: bool
        Average the result over samples.

    Returns
    -------
    Ep: torch.Tensor
        Negative part of the divergence / difference.

    Example
    -------
    >>> import numpy as np
    >>> import torch
    >>> from deepchem.models.losses import get_negative_expectation
    >>> q_samples = torch.tensor([0.5, 1.0, -0.5, -1.0])
    >>> measure = 'JSD'
    >>> result = get_negative_expectation(q_samples, measure)
    """
    import math

    import torch
    log_2 = math.log(2.)

    if measure == 'GAN':
        Eq = torch.nn.functional.softplus(-q_samples) + q_samples
    elif measure == 'JSD':
        Eq = torch.nn.functional.softplus(-q_samples) + q_samples - log_2
    elif measure == 'X2':
        Eq = -0.5 * ((torch.sqrt(q_samples**2) + 1.)**2)
    elif measure == 'KL':
        Eq = torch.exp(q_samples)
    elif measure == 'RKL':
        Eq = q_samples - 1.
    elif measure == 'DV':
        Eq = log_sum_exp(q_samples, 0) - math.log(q_samples.size(0))
    elif measure == 'H2':
        Eq = torch.exp(q_samples) - 1.
    elif measure == 'W1':
        Eq = q_samples
    else:
        raise ValueError('Unknown measure: {}'.format(measure))

    if average_loss:
        return Eq.mean()
    else:
        return Eq


def log_sum_exp(x, axis=None):
    """Log sum exp function.

    Parameters
    ----------
    x: torch.Tensor
        Input tensor
    axis: int
        Axis to perform sum over

    Returns
    -------
    y: torch.Tensor
        Log sum exp of x

    """
    import torch
    x_max = torch.max(x, axis)[0]
    y = torch.log((torch.exp(x - x_max)).sum(axis)) + x_max
    return y

class Loss:
    """A loss function for use in training models."""

    def _compute_tf_loss(self, output, labels):
        """Compute the loss function for TensorFlow tensors.

        The inputs are tensors containing the model's outputs and the labels for a
        batch.  The return value should be a tensor of shape (batch_size) or
        (batch_size, tasks) containing the value of the loss function on each
        sample or sample/task.

        Parameters
        ----------
        output: tensor
            the output of the model
        labels: tensor
            the expected output

        Returns
        -------
        The value of the loss function on each sample or sample/task pair
        """
        raise NotImplementedError("Subclasses must implement this")

    def _create_pytorch_loss(self):
        """Create a PyTorch loss function."""
        raise NotImplementedError("Subclasses must implement this")

class LocalMutualInformationLoss(Loss):
    """
    Local-global encoding loss (comparing a subgraph to the full graph).

    Compares the encodings of two molecular graphs and returns the loss between them based on the measure specified.
    The encodings are generated by two separate encoders in order to maximize the mutual information between the two encodings.

    Parameters
    ----------
    local_enc: torch.Tensor
        Features from a graph convolutional encoder.
    global_enc: torch.Tensor
        Another set of features from a graph convolutional encoder.
    batch_graph_index: graph_index: np.ndarray or torch.tensor, dtype int
        This vector indicates which graph the node belongs with shape [num_nodes,]. Only present in BatchGraphData, not in GraphData objects.
    measure: str
        The divergence measure to use for the unsupervised loss. Options are 'GAN', 'JSD', 'KL', 'RKL', 'X2', 'DV', 'H2', or 'W1'.
    average_loss: bool
        Whether to average the loss over the batch

    Returns
    -------
    loss: torch.Tensor
        Measure of mutual information between the encodings of the two graphs.

    References
    ----------
    .. [1] F.-Y. Sun, J. Hoffmann, V. Verma, and J. Tang, “InfoGraph: Unsupervised and Semi-supervised Graph-Level Representation Learning via Mutual Maximization.” arXiv, Jan. 17, 2020. http://arxiv.org/abs/1908.01000

    Example
    -------
    >>> import numpy as np
    >>> import deepchem.models.losses as losses
    >>> from deepchem.feat.graph_data import BatchGraphData, GraphData
    >>> from deepchem.models.torch_models.infograph import InfoGraphEncoder
    >>> from deepchem.models.torch_models.layers import MultilayerPerceptron
    >>> graph_list = []
    >>> for i in range(3):
    ...     node_features = np.random.rand(5, 10)
    ...     edge_index = np.array([[0, 1, 2, 3, 4], [1, 2, 3, 4, 0]], dtype=np.int64)
    ...     edge_features = np.random.rand(5, 5)
    ...     graph_list.append(GraphData(node_features, edge_index, edge_features))

    >>> batch = BatchGraphData(graph_list).numpy_to_torch()
    >>> num_feat = 10
    >>> edge_dim = 5
    >>> dim = 4
    >>> encoder = InfoGraphEncoder(num_feat, edge_dim, dim)
    >>> encoding, feature_map = encoder(batch)
    >>> g_enc = MultilayerPerceptron(2 * dim, dim)(encoding)
    >>> l_enc = MultilayerPerceptron(dim, dim)(feature_map)
    >>> localloss = losses.LocalMutualInformationLoss()
    >>> loss = localloss._create_pytorch_loss()(l_enc, g_enc, batch.graph_index).detach().numpy()
    """

    def _create_pytorch_loss(self, measure='JSD', average_loss=True,log=True):

        import torch

        def loss(local_enc, global_enc, batch_graph_index):
            device = local_enc.device
            num_graphs = global_enc.shape[0]
            num_nodes = local_enc.shape[0]

            pos_mask = torch.zeros((num_nodes, num_graphs)).to(device)
            neg_mask = torch.ones((num_nodes, num_graphs)).to(device)
            for nodeidx, graphidx in enumerate(batch_graph_index):
                pos_mask[nodeidx][graphidx] = 1.
                neg_mask[nodeidx][graphidx] = 0.

            res = torch.mm(local_enc, global_enc.t())

            E_pos = get_positive_expectation(res * pos_mask, measure,
                                             average_loss)
            E_pos = (E_pos * pos_mask).sum() / pos_mask.sum()
            E_neg = get_negative_expectation(res * neg_mask, measure,
                                             average_loss)
            E_neg = (E_neg * neg_mask).sum() / neg_mask.sum()
            if log:
                return torch.log(1 + torch.exp(E_neg - E_pos + 1e-8))
            else:
                return E_neg - E_pos

        return loss

class KMEANS:
    def __init__(self, n_clusters=20, max_iter=None, verbose=True):
        self.n_clusters = n_clusters
        self.labels = None
        self.dists = None  # shape: [x.shape[0],n_cluster]
        self.centers = None
        self.variation = torch.Tensor([float("Inf")])
        self.verbose = verbose
        self.started = False
        self.representative_samples = None
        self.max_iter = max_iter
        self.count = 0

    def fit_predict(self, x):
        # 随机选择初始中心点，想更快的收敛速度可以借鉴sklearn中的kmeans++初始化方法
        init_row = torch.randint(0, x.shape[0], (self.n_clusters,)).to(x.device)
        init_points = x[init_row]
        self.centers = init_points
        while True:
            # 聚类标记
            self.nearest_center(x)
            # 更新中心点
            self.update_center(x)
            if self.verbose:
                print(self.variation, torch.argmin(self.dists, (0)))
            if torch.abs(self.variation) < 1e-3 and self.max_iter is None:
                break
            elif self.max_iter is not None and self.count == self.max_iter:
                break

            self.count += 1

        self.representative_sample()

    def nearest_center(self, x):
        labels = torch.empty((x.shape[0],)).long().to(x.device)
        dists = torch.empty((0, self.n_clusters)).to(x.device)
        for i, sample in enumerate(x):
            dist = torch.sum(torch.mul(sample - self.centers, sample - self.centers), (1))
            labels[i] = torch.argmin(dist)
            dists = torch.cat([dists, dist.unsqueeze(0)], (0))
        self.labels = labels
        if self.started:
            self.variation = torch.sum(self.dists - dists)
        self.dists = dists
        self.started = True

    def update_center(self, x):
        centers = torch.empty((0, x.shape[1])).to(x.device)
        for i in range(self.n_clusters):
            mask = self.labels == i
            cluster_samples = x[mask]
            centers = torch.cat([centers, torch.mean(cluster_samples, (0)).unsqueeze(0)], (0))
        self.centers = centers

    def representative_sample(self):
        # 查找距离中心点最近的样本，作为聚类的代表样本，更加直观
        self.representative_samples = torch.argmin(self.dists, (0))


class CCL_contrastive_loss_ddp(nn.Module):
    
    def __init__(self, n_clusters=8, omega=0.5):
        super().__init__()
        self.n_clusters = n_clusters
        self.omega = omega
        self.world_size = torch.distributed.get_world_size()
        # self.km = KMEANS(n_clusters=self.n_clusters,max_iter=20,verbose=False)

    def gather_tensor(self,tensor):
        gathered_tensor_list = [torch.zeros_like(tensor) for _ in range(self.world_size)]
        torch.distributed.all_gather(gathered_tensor_list, tensor)
        return torch.cat(gathered_tensor_list, dim=0)
    
    def forward(self, tx_emb, img_emb, logit_scale, smooth):
        # world_size = torch.distributed.get_world_size()
        rank = torch.distributed.get_rank()
        
        # gathered_tx_emb_list = [torch.zeros_like(tx_emb) for _ in range(world_size)]
        # gathered_img_emb_list = [torch.zeros_like(img_emb) for _ in range(world_size)]
        # torch.distributed.all_gather(gathered_tx_emb_list, tx_emb)
        # torch.distributed.all_gather(gathered_img_emb_list, img_emb)
        
        # gathered_tx_emb = torch.cat(gathered_tx_emb_list, dim=0)
        # gathered_img_emb = torch.cat(gathered_img_emb_list, dim=0)
        
        gathered_tx_emb = self.gather_tensor(tx_emb)
        gathered_img_emb = self.gather_tensor(img_emb)
        N = gathered_img_emb.shape[0]
        
        # Cluster on host GPU
        # self.km.fit_predict(gathered_img_emb)
        
        # TODO
        km = KMEANS(n_clusters=self.n_clusters,max_iter=20,verbose=False)
        km.fit_predict(gathered_img_emb)
        cluster_labels = km.labels
        del km
        
        # Build global cluster mask
        cluster_mask = cluster_labels.unsqueeze(0) == cluster_labels.unsqueeze(1) # [N, N]
        cluster_mask = cluster_mask & (~torch.eye(N, dtype=torch.bool, device=tx_emb.device))
        
        mini_batch_size = tx_emb.shape[0]
        global_batch_size = gathered_tx_emb.shape[0]
        start_idx = rank * mini_batch_size
        end_idx = start_idx + mini_batch_size
        
        mini_cluster_mask = cluster_mask[start_idx:end_idx] # [B, N]
        
        logits_val_t2i = (tx_emb @ gathered_img_emb.T) * logit_scale.exp() # [B, N]
        logits_val_i2t = (img_emb @ gathered_tx_emb.T) * logit_scale.exp() # [B, N]
        
        modified_logits_val_t2i = logits_val_t2i.clone()
        modified_logits_val_t2i[mini_cluster_mask] *= self.omega
        
        labels = torch.arange(mini_batch_size, device=tx_emb.device) + rank * mini_batch_size
        loss_t2i = F.cross_entropy(modified_logits_val_t2i, labels, label_smoothing=smooth)
        loss_i2t = F.cross_entropy(logits_val_i2t, labels, label_smoothing=smooth)
        
        loss = (loss_t2i + loss_i2t) / 2.
        return loss


class CCL_contrastive_loss(nn.Module):
    def __init__(self, n_clusters=8, omega=0.5):
        super().__init__()
        self.n_clusters = n_clusters
        self.omega = omega
        
    def forward(self, tx_emb, img_emb, logit_scale, smooth):
        # tx_emb: [B, D], img_emb: [B, D]
        B = tx_emb.shape[0]
        world_size = torch.distributed.get_world_size()
        rank = torch.distributed.get_rank()

        # Gather embeddings from all ranks
        gathered_tx_emb_list = [torch.zeros_like(tx_emb) for _ in range(world_size)]
        gathered_img_emb_list = [torch.zeros_like(img_emb) for _ in range(world_size)]
        torch.distributed.all_gather(gathered_tx_emb_list, tx_emb)
        torch.distributed.all_gather(gathered_img_emb_list, img_emb)

        gathered_tx_emb = torch.cat(gathered_tx_emb_list, dim=0)  # [N, D]
        gathered_img_emb = torch.cat(gathered_img_emb_list, dim=0)  # [N, D]

        N = gathered_img_emb.shape[0]

        # Cluster on CPU
        km = KMEANS(n_clusters=self.n_clusters,max_iter=20,verbose=False,device=tx_emb.device)
        km.fit_predict(gathered_img_emb.to(tx_emb.device))  # [N]
        cluster_labels = km.labels

        # Build global cluster mask
        cluster_mask = cluster_labels.unsqueeze(0) == cluster_labels.unsqueeze(1)  # [N, N]
        cluster_mask = cluster_mask & (~torch.eye(N, dtype=torch.bool, device=tx_emb.device))

        # Compute local logits
        logits_val = (tx_emb @ img_emb.T) * logit_scale.exp()  # [B, B]

        # Get corresponding sub-mask for current rank
        start_idx = rank * B
        end_idx = start_idx + B
        local_cluster_mask = cluster_mask[start_idx:end_idx, :N]  # [B, N]

        # Vectorized operation to apply omega
        pos_mask = (local_cluster_mask & (local_cluster_mask.sum(dim=1, keepdim=True) > 0))
        pos_indices = pos_mask.nonzero(as_tuple=True)
        modified_logits_val = logits_val.clone()
        modified_logits_val[pos_indices] *= self.omega

        # Compute loss
        labels = torch.arange(B, device=tx_emb.device)
        loss_text_to_img = F.cross_entropy(modified_logits_val, labels, label_smoothing=smooth)
        loss_img_to_text = F.cross_entropy(logits_val.T, labels, label_smoothing=smooth)
        loss = (loss_text_to_img + loss_img_to_text) / 2

        return loss.float()